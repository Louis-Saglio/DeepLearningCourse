{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# noinspection PyUnresolvedReferences\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def reformat(x_data):\n",
    "    \"\"\"\n",
    "    Reformats the data to the format acceptable for convolutional layers\n",
    "    :param x_data: input array\n",
    "    :return: reshaped input and labels\n",
    "    \"\"\"\n",
    "    img_size = int(np.sqrt(x_data.shape[-1]))\n",
    "    return x_data.reshape((-1, img_size, img_size, 1)).astype(np.float32)\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Function to (download and) load the MNIST data\n",
    "    \"\"\"\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    return (\n",
    "        reformat(mnist.train.images),\n",
    "        mnist.train.labels,\n",
    "        reformat(mnist.validation.images),\n",
    "        mnist.validation.labels,\n",
    "    )\n",
    "\n",
    "\n",
    "def randomize(x_data, y_data):\n",
    "    \"\"\" Randomizes the order of data samples and their corresponding labels\"\"\"\n",
    "    permutation = np.random.permutation(y_data.shape[0])\n",
    "    return x_data[permutation, :, :, :], y_data[permutation]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT, IMAGE_WIDTH = 28, 28"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "input_layer = tf.placeholder(tf.float32, shape=[None, IMAGE_HEIGHT, IMAGE_WIDTH, 1], name='X')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "conv_layer_0_filter_size = 5\n",
    "conv_layer_0_stride = 1\n",
    "conv_layer_0_filters_number = 16  # what does this variable means ? Should be 23² (28 - 5) ^ 2\n",
    "\n",
    "conv_layer_0_weights = tf.get_variable(\n",
    "    'conv_layer_0_weights',\n",
    "    dtype=tf.float32,\n",
    "    shape=[\n",
    "       conv_layer_0_filter_size,\n",
    "       conv_layer_0_filter_size,\n",
    "       input_layer.get_shape().as_list()[-1],\n",
    "       conv_layer_0_filters_number\n",
    "    ],\n",
    "    initializer=tf.truncated_normal_initializer(stddev=0.01)\n",
    ")\n",
    "\n",
    "conv_layer_0_biases = tf.get_variable(\n",
    "    \"conv_layer_0_biases\",\n",
    "    dtype=tf.float32,\n",
    "    initializer=tf.constant(0.0, shape=[conv_layer_0_filters_number], dtype=tf.float32)\n",
    ")\n",
    "\n",
    "conv_layer_0 = tf.nn.conv2d(\n",
    "    input_layer,\n",
    "    conv_layer_0_weights,\n",
    "    strides=[1, conv_layer_0_stride, conv_layer_0_stride, 1],\n",
    "    padding=\"SAME\"\n",
    ")\n",
    "\n",
    "conv_layer_0 += conv_layer_0_biases\n",
    "conv_layer_0 = tf.nn.relu(conv_layer_0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "pool_layer_0_size = 2\n",
    "pool_layer_0 = tf.nn.max_pool(\n",
    "    conv_layer_0,\n",
    "    ksize=[1, pool_layer_0_size, pool_layer_0_size, 1],  # Why 4 dimensions ?\n",
    "    strides=[1, pool_layer_0_size, pool_layer_0_size, 1],\n",
    "    padding=\"SAME\",\n",
    "    name=\"pool_layer_0\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "conv_layer_1_filter_size = 5\n",
    "conv_layer_1_stride = 1\n",
    "conv_layer_1_filters_number = 32  # what does this variable means ? Should be 23² (28 - 5) ^ 2\n",
    "\n",
    "conv_layer_1_weights = tf.get_variable(\n",
    "    'conv_layer_1_weights',\n",
    "    dtype=tf.float32,\n",
    "    shape=[\n",
    "       conv_layer_1_filter_size,\n",
    "       conv_layer_1_filter_size,\n",
    "       pool_layer_0.get_shape().as_list()[-1],\n",
    "       conv_layer_1_filters_number\n",
    "    ],\n",
    "    initializer=tf.truncated_normal_initializer(stddev=0.01)\n",
    ")\n",
    "\n",
    "conv_layer_1_biases = tf.get_variable(\n",
    "    \"conv_layer_1_biases\",\n",
    "    dtype=tf.float32,\n",
    "    initializer=tf.constant(0.0, shape=[conv_layer_1_filters_number], dtype=tf.float32)\n",
    ")\n",
    "\n",
    "conv_layer_1 = tf.nn.conv2d(\n",
    "    pool_layer_0,\n",
    "    conv_layer_1_weights,\n",
    "    strides=[1, conv_layer_1_stride, conv_layer_1_stride, 1],\n",
    "    padding=\"SAME\"\n",
    ")\n",
    "\n",
    "conv_layer_1 += conv_layer_1_biases\n",
    "conv_layer_1 = tf.nn.relu(conv_layer_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "pool_layer_1_size = 2\n",
    "pool_layer_1 = tf.nn.max_pool(\n",
    "    conv_layer_1,\n",
    "    ksize=[1, pool_layer_1_size, pool_layer_1_size, 1],  # Why 4 dimensions ?\n",
    "    strides=[1, pool_layer_1_size, pool_layer_1_size, 1],\n",
    "    padding=\"SAME\",\n",
    "    name=\"pool_layer_1\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "flat_layer = tf.reshape(\n",
    "    tensor=pool_layer_1,\n",
    "    shape=[-1, pool_layer_1.shape[1:4].num_elements()]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "fc_layer_0_size = 128\n",
    "fc_layer_0_weights = tf.get_variable(\n",
    "    name='fc_layer_0_weights',\n",
    "    dtype=tf.float32,\n",
    "    shape=[flat_layer.shape[1], fc_layer_0_size],\n",
    "    initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    ")\n",
    "fc_layer_0_biases = tf.get_variable(\n",
    "    name='fc_layer_0_biases',\n",
    "    dtype=tf.float32,\n",
    "    initializer=tf.constant(0.0, shape=[fc_layer_0_size], dtype=tf.float32),\n",
    ")\n",
    "\n",
    "fc_layer_0 = tf.matmul(flat_layer, fc_layer_0_weights)\n",
    "fc_layer_0 = tf.add(fc_layer_0, fc_layer_0_biases)\n",
    "fc_layer_0 = tf.nn.relu(fc_layer_0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "CLASSES_NUMBER = 10\n",
    "output_layer_weights = tf.get_variable(\n",
    "    name='output_layer_weights',\n",
    "    dtype=tf.float32,\n",
    "    shape=[fc_layer_0.shape[1], CLASSES_NUMBER],\n",
    "    initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    ")\n",
    "output_layer_biases = tf.get_variable(\n",
    "    name='output_layer_biases',\n",
    "    dtype=tf.float32,\n",
    "    initializer=tf.constant(0.0, shape=[CLASSES_NUMBER], dtype=tf.float32),\n",
    ")\n",
    "\n",
    "output_layer = tf.matmul(fc_layer_0, output_layer_weights)\n",
    "output_layer = tf.add(output_layer, output_layer_biases)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(?, 28, 28, 1)\n",
      "(?, 28, 28, 16)\n",
      "(?, 14, 14, 16)\n",
      "(?, 14, 14, 32)\n",
      "(?, 7, 7, 32)\n",
      "(?, 1568)\n",
      "(?, 128)\n",
      "(?, 10)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(input_layer.shape)\n",
    "print(conv_layer_0.shape)\n",
    "print(pool_layer_0.shape)\n",
    "print(conv_layer_1.shape)\n",
    "print(pool_layer_1.shape)\n",
    "print(flat_layer.shape)\n",
    "print(fc_layer_0.shape)\n",
    "print(output_layer.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-1ad064045209>:9: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "output_train = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, CLASSES_NUMBER],\n",
    "    name='output_train'\n",
    ")\n",
    "loss = tf.reduce_mean(\n",
    "    input_tensor=tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=output_train,\n",
    "        logits=output_layer,\n",
    "    ),\n",
    "    name='loss',\n",
    ")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001, name='Adam-optimizer').minimize(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(\n",
    "    input_tensor=tf.cast(\n",
    "        x=tf.equal(\n",
    "            x=tf.argmax(output_layer, 1),\n",
    "            y=tf.argmax(output_train, 1),\n",
    "            name='correct_prediction'\n",
    "        ),\n",
    "        dtype=tf.float32,\n",
    "    ),\n",
    "    name='accuracy',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4ebbc3e1e6a9>:14: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/louis/anaconda3/envs/DeepLearningCourse/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/louis/anaconda3/envs/DeepLearningCourse/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/louis/anaconda3/envs/DeepLearningCourse/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/louis/anaconda3/envs/DeepLearningCourse/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/louis/anaconda3/envs/DeepLearningCourse/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# noinspection PyShadowingNames\n",
    "def print_accuracy(loss, accuracy, input_layer, output_train, x_valid, y_valid, epoch_id):\n",
    "    validation_data_loss, validation_data_accuracy = session.run(\n",
    "            fetches=[loss, accuracy],\n",
    "            feed_dict={input_layer: x_valid, output_train: y_valid}\n",
    "        )\n",
    "    print(f\"Epoch: {epoch_id}, validation loss: {validation_data_loss:.2f}, validation accuracy: {validation_data_accuracy:.01%}\" )\n",
    "    print(\"-\" * 60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch: 0, validation loss: 2.30, validation accuracy: 6.7%\n",
      "------------------------------------------------------------\n",
      "Epoch: 0, validation loss: 0.49, validation accuracy: 85.1%\n",
      "------------------------------------------------------------\n",
      "Epoch: 1, validation loss: 0.29, validation accuracy: 91.3%\n",
      "------------------------------------------------------------\n",
      "Epoch: 2, validation loss: 0.21, validation accuracy: 93.4%\n",
      "------------------------------------------------------------\n",
      "Epoch: 3, validation loss: 0.16, validation accuracy: 95.0%\n",
      "------------------------------------------------------------\n",
      "Epoch: 4, validation loss: 0.14, validation accuracy: 95.7%\n",
      "------------------------------------------------------------\n",
      "Epoch: 5, validation loss: 0.11, validation accuracy: 96.7%\n",
      "------------------------------------------------------------\n",
      "Epoch: 6, validation loss: 0.10, validation accuracy: 96.9%\n",
      "------------------------------------------------------------\n",
      "Epoch: 7, validation loss: 0.10, validation accuracy: 97.0%\n",
      "------------------------------------------------------------\n",
      "Epoch: 8, validation loss: 0.08, validation accuracy: 97.5%\n",
      "------------------------------------------------------------\n",
      "Epoch: 9, validation loss: 0.07, validation accuracy: 97.9%\n",
      "------------------------------------------------------------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "epochs_number = 10\n",
    "batch_size = 100\n",
    "\n",
    "initializer = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(initializer)\n",
    "    for epoch_id in range(epochs_number):\n",
    "        x_train, y_train = randomize(x_train, y_train)\n",
    "        if epoch_id == 0:\n",
    "            print_accuracy(loss, accuracy, input_layer, output_train, x_train, y_train, epoch_id)\n",
    "        for batch_id in range(batch_size):\n",
    "            start = batch_id * batch_size\n",
    "            end = (batch_id + 1) * batch_size\n",
    "            x_batch = x_train[start:end]\n",
    "            y_batch = y_train[start:end]\n",
    "            session.run(\n",
    "                fetches=optimizer,\n",
    "                feed_dict={\n",
    "                    input_layer: x_batch,\n",
    "                    output_train: y_batch\n",
    "                }\n",
    "            )\n",
    "        print_accuracy(loss, accuracy, input_layer, output_train, x_train, y_train, epoch_id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}