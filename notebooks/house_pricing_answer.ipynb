{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "feature_nbr = 2\n",
    "columns= ['LotArea', 'TotalBsmtSF']\n",
    "# n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(mode='train', columns= ['LotArea', 'TotalBsmtSF']):\n",
    "    \"\"\"\n",
    "    Function to (download and) load the MNIST data\n",
    "    :param mode: train or test\n",
    "    :return: images and the corresponding labels\n",
    "    \"\"\"\n",
    "    \n",
    "    if mode == \"train\":\n",
    "        data = pd.read_csv('../data/house-prices-advanced-regression-techniques/train.csv')\n",
    "        return data[columns].to_numpy(), data['SalePrice'].to_numpy()\n",
    "    else:\n",
    "        data = pd.read_csv('../data/house-prices-advanced-regression-techniques/test.csv')\n",
    "        return data[columns].to_numpy()\n",
    "        \n",
    "\n",
    "\n",
    "def randomize(x, y):\n",
    "    \"\"\" Randomizes the order of data samples and their corresponding labels\"\"\"\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    shuffled_x = x[permutation, :]\n",
    "    shuffled_y = y[permutation]\n",
    "    return shuffled_x, shuffled_y\n",
    "\n",
    "\n",
    "def get_next_batch(x, y, start, end):\n",
    "    x_batch = x[start:end]\n",
    "    y_batch = y[start:end]\n",
    "    return x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t1460\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "x_train, y_train = load_data(mode='train',columns=columns)\n",
    "x_test = load_data(mode='test',columns=columns)\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "x_train:\t(1460, 2)\n",
      "y_train:\t(1460,)\n",
      "x_test:\t(1459, 2)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('x_train:\\t{}'.format(x_train.shape))\n",
    "print('y_train:\\t{}'.format(y_train.shape))\n",
    "print('x_test:\\t{}'.format(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "epochs = 100             # Total number of training epochs\n",
    "batch_size = 100        # Training batch size\n",
    "display_freq = 100      # Frequency of displaying the training results\n",
    "learning_rate = 0.001   # The optimization initial learning rate\n",
    "\n",
    "h1 = 200                # number of nodes in the 1st hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# weight and bais wrappers\n",
    "def weight_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a weight variable with appropriate initialization\n",
    "    :param name: weight name\n",
    "    :param shape: weight shape\n",
    "    :return: initialized weight variable\n",
    "    \"\"\"\n",
    "    return tf.get_variable(\n",
    "        'W_' + name,\n",
    "        dtype=tf.float32,\n",
    "        shape=shape,\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.01)\n",
    "    )\n",
    "\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a bias variable with appropriate initialization\n",
    "    :param name: bias variable name\n",
    "    :param shape: bias variable shape\n",
    "    :return: initialized bias variable\n",
    "    \"\"\"\n",
    "    return tf.get_variable(\n",
    "        'b_' + name,\n",
    "        dtype=tf.float32,\n",
    "        initializer=tf.constant(0., shape=shape, dtype=tf.float32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def fc_layer(x, num_units, name, use_relu=True):\n",
    "    \"\"\"\n",
    "    Create a fully-connected layer\n",
    "    :param x: input from previous layer\n",
    "    :param num_units: number of hidden units in the fully-connected layer\n",
    "    :param name: layer name\n",
    "    :param use_relu: boolean to add ReLU non-linearity (or not)\n",
    "    :return: The output array\n",
    "    \"\"\"\n",
    "    in_dim = x.get_shape()[1]\n",
    "    W = weight_variable(name, shape=[in_dim, num_units])\n",
    "    b = bias_variable(name, [num_units])\n",
    "    layer = tf.matmul(x, W)\n",
    "    layer += b\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the graph for the linear model\n",
    "# Placeholders for inputs (x) and outputs(y)\n",
    "x = tf.placeholder(tf.float32, shape=[None, feature_nbr], name='X')\n",
    "y = tf.placeholder(tf.float32, shape=[None], name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a fully-connected layer with h1 nodes as hidden layer\n",
    "fc1 = fc_layer(x, h1, 'FC1', use_relu=True)\n",
    "# Create a fully-connected layer with n_classes nodes as output layer\n",
    "y_pred = fc_layer(fc1, 1, 'OUT', use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the loss function, optimizer, and accuracy\n",
    "loss = tf.reduce_mean(tf.squared_difference(y, y_pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
    "#correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1), name='correct_pred')\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "# Network predictions\n",
    "#cls_prediction = tf.argmax(y_pred, axis=1, name='predictions')\n",
    "# TODO : metric RMSLE : root mean squarreds log  error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the op for initializing all variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training epoch: 1\n",
      "Training epoch: 2\n",
      "Training epoch: 3\n",
      "Training epoch: 4\n",
      "Training epoch: 5\n",
      "Training epoch: 6\n",
      "Training epoch: 7\n",
      "Training epoch: 8\n",
      "Training epoch: 9\n",
      "Training epoch: 10\n",
      "Training epoch: 11\n",
      "Training epoch: 12\n",
      "Training epoch: 13\n",
      "Training epoch: 14\n",
      "Training epoch: 15\n",
      "Training epoch: 16\n",
      "Training epoch: 17\n",
      "Training epoch: 18\n",
      "Training epoch: 19\n",
      "Training epoch: 20\n",
      "Training epoch: 21\n",
      "Training epoch: 22\n",
      "Training epoch: 23\n",
      "Training epoch: 24\n",
      "Training epoch: 25\n",
      "Training epoch: 26\n",
      "Training epoch: 27\n",
      "Training epoch: 28\n",
      "Training epoch: 29\n",
      "Training epoch: 30\n",
      "Training epoch: 31\n",
      "Training epoch: 32\n",
      "Training epoch: 33\n",
      "Training epoch: 34\n",
      "Training epoch: 35\n",
      "Training epoch: 36\n",
      "Training epoch: 37\n",
      "Training epoch: 38\n",
      "Training epoch: 39\n",
      "Training epoch: 40\n",
      "Training epoch: 41\n",
      "Training epoch: 42\n",
      "Training epoch: 43\n",
      "Training epoch: 44\n",
      "Training epoch: 45\n",
      "Training epoch: 46\n",
      "Training epoch: 47\n",
      "Training epoch: 48\n",
      "Training epoch: 49\n",
      "Training epoch: 50\n",
      "Training epoch: 51\n",
      "Training epoch: 52\n",
      "Training epoch: 53\n",
      "Training epoch: 54\n",
      "Training epoch: 55\n",
      "Training epoch: 56\n",
      "Training epoch: 57\n",
      "Training epoch: 58\n",
      "Training epoch: 59\n",
      "Training epoch: 60\n",
      "Training epoch: 61\n",
      "Training epoch: 62\n",
      "Training epoch: 63\n",
      "Training epoch: 64\n",
      "Training epoch: 65\n",
      "Training epoch: 66\n",
      "Training epoch: 67\n",
      "Training epoch: 68\n",
      "Training epoch: 69\n",
      "Training epoch: 70\n",
      "Training epoch: 71\n",
      "Training epoch: 72\n",
      "Training epoch: 73\n",
      "Training epoch: 74\n",
      "Training epoch: 75\n",
      "Training epoch: 76\n",
      "Training epoch: 77\n",
      "Training epoch: 78\n",
      "Training epoch: 79\n",
      "Training epoch: 80\n",
      "Training epoch: 81\n",
      "Training epoch: 82\n",
      "Training epoch: 83\n",
      "Training epoch: 84\n",
      "Training epoch: 85\n",
      "Training epoch: 86\n",
      "Training epoch: 87\n",
      "Training epoch: 88\n",
      "Training epoch: 89\n",
      "Training epoch: 90\n",
      "Training epoch: 91\n",
      "Training epoch: 92\n",
      "Training epoch: 93\n",
      "Training epoch: 94\n",
      "Training epoch: 95\n",
      "Training epoch: 96\n",
      "Training epoch: 97\n",
      "Training epoch: 98\n",
      "Training epoch: 99\n",
      "Training epoch: 100\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Create an interactive session (to keep the session in the other cells)\n",
    "sess = tf.InteractiveSession()\n",
    "# Initialize all variables\n",
    "sess.run(init)\n",
    "# Number of training iterations in each epoch\n",
    "num_tr_iter = int(len(y_train) / batch_size)\n",
    "for epoch in range(epochs):\n",
    "    print('Training epoch: {}'.format(epoch + 1))\n",
    "    # Randomly shuffle the training data at the beginning of each epoch \n",
    "    x_train, y_train = randomize(x_train, y_train)\n",
    "    for iteration in range(num_tr_iter):\n",
    "        start = iteration * batch_size\n",
    "        end = (iteration + 1) * batch_size\n",
    "        x_batch, y_batch = get_next_batch(x_train, y_train, start, end)\n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        feed_dict_batch = {x: x_batch, y: y_batch}\n",
    "        sess.run(optimizer, feed_dict=feed_dict_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict sur le train \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_train_pred = sess.run(y_pred, feed_dict={x: x_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric sur le train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.5503599219084664"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "np.sqrt(mean_squared_log_error( y_train, y_train_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict sur le test \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = sess.run(y_pred, feed_dict={x: x_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric sur le train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.5503599219084664"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 22
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "np.sqrt(mean_squared_log_error( y_train, y_train_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultat kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 0.56624"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Préparation pour kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[     nan],\n       [75210.31],\n       [43802.62],\n       [87577.75],\n       [91536.6 ]], dtype=float32)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 23
    }
   ],
   "source": [
    "y_test_pred[660:665]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1459"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 24
    }
   ],
   "source": [
    "len(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('../data/house-prices-advanced-regression-techniques/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_result = data_test[\"Id\"].astype(int)\n",
    "SalePrice = pd.Series(y_test_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame([data_result,SalePrice]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_result.columns = ['Id', 'SalePrice']\n",
    "df_result[\"Id\"] = df_result[\"Id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_result.to_csv(\"predict.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}